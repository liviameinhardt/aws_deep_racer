{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of the function in [this article](https://medium.com/@anshml/craft-a-powerful-reward-function-in-student-league-81925c56a11e)\n",
    "\n",
    "Decisions:\n",
    "1. **Distance Reward**:\n",
    "   - Encourages the car to stay near the center with an exponential curve for gradual feedback.\n",
    "2. **Steering Penalty**:\n",
    "   - Reduces reward for steering above 15 degrees to minimize zig-zagging.\n",
    "3. **Speed Reward**:\n",
    "   - Motivates maintaining a speed close to 1 m/s, with an exponential penalty for deviation.\n",
    "4. **Off-Track Penalty**:\n",
    "   - Heavily penalizes when all wheels go off-track to enforce strict adherence.\n",
    "\n",
    "This function balances speed and precision, aligning with the competition's objectives. Let me know if you'd like any adjustments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    \"\"\"\n",
    "    Reward function for AWS DeepRacer to incentivize center line adherence,\n",
    "    controlled steering, and speed maintenance.\n",
    "    \"\"\"\n",
    "    # Extract parameters\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    track_width = params['track_width']\n",
    "    steering_angle = params['steering_angle']\n",
    "    speed = params['speed']\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "    \n",
    "    # Center alignment reward\n",
    "    distance_reward = 1 - (distance_from_center / (0.5 * track_width))**0.4\n",
    "\n",
    "    # Speed reward\n",
    "    SPEED_THRESHOLD = 1.0  # m/s\n",
    "    speed_diff = abs(SPEED_THRESHOLD - speed)\n",
    "    max_speed_diff = 0.2 #set it carefully in range [0.01,0.3] \n",
    "    speed_reward = max(1e-3, 1 - (speed_diff / max_speed_diff)**0.5) #never set negative or zero rewards\n",
    "\n",
    "    # Combine rewards and handle off-track penalty\n",
    "    if not all_wheels_on_track:\n",
    "        reward = 1e-3  # Penalize heavily if off-track\n",
    "    else:\n",
    "        reward = (distance_reward * 2) + (speed_reward * 10)\n",
    "    \n",
    "    return float(reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, from [this article](https://blog.gofynd.com/how-we-broke-into-the-top-1-of-the-aws-deepracer-virtual-circuit-573ba46c275)\n",
    "\n",
    "Key Decisions and Design\n",
    "\n",
    "1. **Speed Component**:\n",
    "   - Encourages the car to maintain an optimal speed range using a Gaussian function centered around the mean of min and max speeds.\n",
    "\n",
    "2. **Distance Component**:\n",
    "   - Penalizes deviation from the center of the track, favoring paths close to the racing line.\n",
    "\n",
    "3. **Heading Component**:\n",
    "   - Rewards alignment of the car's heading with the direction of the track.\n",
    "\n",
    "4. **Curve Bonus**:\n",
    "   - Provides additional rewards for navigating sharp turns effectively, ensuring stability.\n",
    "\n",
    "5. **Progress Reward**:\n",
    "   - Incentivizes steady progress along the track, exponentially increasing with milestones.\n",
    "\n",
    "6. **Immediate and Long-Term Components**:\n",
    "   - Combines both short-term actions and overall track progress for balanced learning.\n",
    "\n",
    "7. **Avoid Unpardonable Actions**:\n",
    "   - Penalizes heavily for leaving the track or making unreasonably sharp turns.\n",
    "\n",
    "---\n",
    "\n",
    "This reward function reflects the detailed principles discussed in the article and can guide a DeepRacer model towards better performance. Let me know if you’d like more customization or detailed parameter adjustments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Classe para armazenar os parâmetros anteriores\n",
    "class PARAMS:\n",
    "    prev_speed = None\n",
    "    prev_steering_angle = None \n",
    "    prev_steps = None\n",
    "    prev_direction_diff = None\n",
    "    prev_normalized_distance_from_route = None\n",
    "    unpardonable_action = False\n",
    "    waypoints = []\n",
    "    optimal_speed = []\n",
    "    intermediate_progress = [0] * 11  # Para bônus de progresso intermediário\n",
    "\n",
    "# Função de recompensa\n",
    "def reward_function(params):\n",
    "    # Parâmetros do episódio\n",
    "    heading = params['heading']\n",
    "    vehicle_x = params['x']\n",
    "    vehicle_y = params['y']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    steps = params['steps']\n",
    "    steering_angle = params['steering_angle']\n",
    "    speed = params['speed']\n",
    "    progress = params['progress']\n",
    "\n",
    "    # Reinicializar parâmetros se for um novo episódio\n",
    "    if PARAMS.prev_steps is None or steps < PARAMS.prev_steps:\n",
    "        PARAMS.prev_speed = None\n",
    "        PARAMS.prev_steering_angle = None\n",
    "        PARAMS.prev_direction_diff = None\n",
    "        PARAMS.prev_normalized_distance_from_route = None\n",
    "\n",
    "    # Cálculo da direção da rota\n",
    "    next_route_point_x = params['next_waypoint'][0]\n",
    "    next_route_point_y = params['next_waypoint'][1]\n",
    "    route_direction = math.atan2(next_route_point_y - vehicle_y, next_route_point_x - vehicle_x)\n",
    "    route_direction = math.degrees(route_direction)\n",
    "    direction_diff = route_direction - heading\n",
    "\n",
    "    # Normalização do desvio de direção\n",
    "    direction_diff = (direction_diff + 360) % 360\n",
    "    if direction_diff > 180:\n",
    "        direction_diff -= 360\n",
    "\n",
    "    # Recompensa de direção\n",
    "    heading_reward = math.cos(abs(direction_diff) * (math.pi / 180)) ** 10\n",
    "    if abs(direction_diff) <= 20:\n",
    "        heading_reward = math.cos(abs(direction_diff) * (math.pi / 180)) ** 4\n",
    "\n",
    "    # Verificar se a velocidade caiu\n",
    "    has_speed_dropped = PARAMS.prev_speed is not None and PARAMS.prev_speed > speed\n",
    "    speed_maintain_bonus = min(speed / PARAMS.prev_speed, 1) if has_speed_dropped else 1\n",
    "\n",
    "    # Penalizar piora no desvio de direção\n",
    "    heading_decrease_bonus = 0\n",
    "    if PARAMS.prev_direction_diff is not None:\n",
    "        if abs(PARAMS.prev_direction_diff / direction_diff) > 1:\n",
    "            heading_decrease_bonus = min(10, abs(PARAMS.prev_direction_diff / direction_diff))\n",
    "\n",
    "    # Verificar alteração no ângulo de direção\n",
    "    has_steering_angle_changed = (\n",
    "        PARAMS.prev_steering_angle is not None and\n",
    "        not math.isclose(PARAMS.prev_steering_angle, steering_angle)\n",
    "    )\n",
    "    steering_angle_maintain_bonus = 1\n",
    "    if abs(direction_diff) < 10:\n",
    "        steering_angle_maintain_bonus *= 2\n",
    "    if PARAMS.prev_direction_diff is not None and abs(PARAMS.prev_direction_diff) > abs(direction_diff):\n",
    "        steering_angle_maintain_bonus *= 2\n",
    "\n",
    "    # Recompensa por manter distância da rota\n",
    "    distance_reduction_bonus = 1\n",
    "    if PARAMS.prev_normalized_distance_from_route is not None:\n",
    "        distance_reduction_bonus = min(\n",
    "            abs(PARAMS.prev_normalized_distance_from_route / distance_from_center), 2\n",
    "        )\n",
    "\n",
    "    # Recompensas principais\n",
    "    HC = (10 * heading_reward * steering_angle_maintain_bonus)\n",
    "    DC = (10 * distance_reduction_bonus)\n",
    "    SC = (5 * speed_maintain_bonus)\n",
    "    IC = (HC + DC + SC) ** 2 + (HC * DC * SC)\n",
    "\n",
    "    if PARAMS.unpardonable_action:\n",
    "        IC = 1e-3\n",
    "\n",
    "    # Recompensa de longo prazo\n",
    "    curve_bonus = 0  # Adicione lógica, se necessário\n",
    "    intermediate_progress_bonus = 0\n",
    "    pi = int(progress // 10)\n",
    "    if pi != 0 and PARAMS.intermediate_progress[pi] == 0:\n",
    "        if pi == 10:\n",
    "            intermediate_progress_bonus = progress ** 14\n",
    "        else:\n",
    "            intermediate_progress_bonus = progress ** (5 + 0.75 * pi)\n",
    "        PARAMS.intermediate_progress[pi] = intermediate_progress_bonus\n",
    "\n",
    "    LC = curve_bonus + intermediate_progress_bonus\n",
    "    reward = max(IC + LC, 1e-3)\n",
    "\n",
    "    # Atualizar parâmetros anteriores\n",
    "    PARAMS.prev_speed = speed\n",
    "    PARAMS.prev_steering_angle = steering_angle\n",
    "    PARAMS.prev_direction_diff = direction_diff\n",
    "    PARAMS.prev_steps = steps\n",
    "    PARAMS.prev_normalized_distance_from_route = distance_from_center\n",
    "\n",
    "    return reward\n",
    "\n",
    "# Função para calcular a recompensa de velocidade\n",
    "def calculate_speed_reward(speed, i, nsteps):\n",
    "    MIN_SPEED = 2.0\n",
    "    MAX_SPEED = 4.0\n",
    "    sigma_speed = abs(MAX_SPEED - MIN_SPEED) / 6.0\n",
    "    optimal_speed = 0\n",
    "\n",
    "    if i + nsteps < len(PARAMS.waypoints):\n",
    "        optimal_speed = min(PARAMS.optimal_speed[i:(i + nsteps) % len(PARAMS.waypoints)])\n",
    "    else:\n",
    "        optimal_speed = min(\n",
    "            min(PARAMS.optimal_speed[i:]),\n",
    "            min(PARAMS.optimal_speed[:(i + nsteps) % len(PARAMS.waypoints) + 1])\n",
    "        )\n",
    "    optimal_speed = min(MAX_SPEED, optimal_speed)\n",
    "    return math.exp(-0.5 * abs(speed - optimal_speed) ** 2 / sigma_speed ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the implementation from [this article](https://medium.com/@marsmans/how-i-got-into-the-top-2-in-aws-deepracer-32127a364212)\n",
    "\n",
    "### Key Design Decisions\n",
    "\n",
    "1. **Distance from Center**:\n",
    "   - Rewards staying close to the center line with a linear penalty as the car drifts outward.\n",
    "\n",
    "2. **Steering Angle**:\n",
    "   - Introduces a penalty for sharp turns (greater than 15 degrees) to encourage smoother driving and minimize zig-zagging.\n",
    "\n",
    "3. **Speed Optimization**:\n",
    "   - Incentivizes speeds within an optimal range (1.0–4.0 m/s). Models are penalized for excessive or insufficient speed.\n",
    "\n",
    "4. **Progress-Based Reward**:\n",
    "   - Directly ties the reward to the percentage of the track completed relative to steps taken, promoting efficiency.\n",
    "\n",
    "5. **Off-Track Penalty**:\n",
    "   - Implements a significant penalty for leaving the track, encouraging strict adherence to the racing line.\n",
    "\n",
    "6. **Custom Adjustments**:\n",
    "   - Encourages testing different weights for distance, speed, and progress rewards based on specific track challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    \"\"\"\n",
    "    Example of rewarding the agent to follow center line\n",
    "    \"\"\"\n",
    "\n",
    "    reward = 1e-3\n",
    "    # Read input parameters\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "\n",
    "    # Calculate 3 markers that are at varying distances away from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 2.0\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1  # getting close to off track\n",
    "\n",
    "    # Incentivize going fast on straight ways and slower on curves\n",
    "    steering_angle = params['steering_angle']\n",
    "    speed = params['speed']\n",
    "    if -5 < steering_angle < 5:\n",
    "        if speed > 2.5:\n",
    "            reward += 2.0\n",
    "        elif speed > 2.0:\n",
    "            reward += 1.0\n",
    "    elif -15 > steering_angle or steering_angle > 15:\n",
    "        if speed < 1.8:\n",
    "            reward += 1.0\n",
    "        elif speed < 2.2:\n",
    "            reward += 0.5\n",
    "\n",
    "    #Incentivizing fewer steps\n",
    "    steps = params['steps']\n",
    "    progress = params['progress']\n",
    "    step_reward = (progress/steps)*10\n",
    "    reward += step_reward\n",
    "\n",
    "\n",
    "    return float(reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lívia\n",
    "\n",
    "1. entender as funcoes que foram implementadas nos post do medium\n",
    "2. escolher ideias que mais façam sentido num primeiro momento\n",
    "3. treinar modelo \n",
    "\n",
    "- repetir até que pareça bom o suficiente:\n",
    "    4. avaliar o que pode ser melhorado\n",
    "    5. mudar funcao \n",
    "\n",
    "6. copiar o modelo \n",
    "7. comparar com o do grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def reward_function(params):\n",
    "    \"\"\"\n",
    "    Função de recompensa para direção suave, rápida e consistente\n",
    "    \"\"\"\n",
    "    # Extrair parâmetros\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    steering_angle = params['steering_angle']\n",
    "    speed = params['speed']\n",
    "    steps = params['steps']\n",
    "    progress = params['progress']\n",
    "    heading = params['heading']\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "\n",
    "    # Penalização por sair da pista\n",
    "    if not all_wheels_on_track:\n",
    "        return 1e-3\n",
    "\n",
    "    # Recompensa por adesão à linha central\n",
    "    center_reward = max(1e-3, 1 - (distance_from_center / (0.5 * track_width))**0.4)\n",
    "\n",
    "    # Penalização para curvas muito fechadas e alta velocidade\n",
    "    if abs(steering_angle) > 15 and speed > 1.8:\n",
    "        steering_penalty = 0.5  # Reduz recompensa em curvas fechadas com alta velocidade\n",
    "    else:\n",
    "        steering_penalty = 1.0\n",
    "\n",
    "    # Recompensa por velocidade ideal\n",
    "    if abs(steering_angle) < 10:  # Retas\n",
    "        speed_reward = max(1e-3, 1 - abs(speed - 2.5) / 2.5)\n",
    "    else:  # Curvas\n",
    "        speed_reward = max(1e-3, 1 - abs(speed - 1.8) / 1.8)\n",
    "\n",
    "    # Recompensa por progresso (proporcional à eficiência dos passos)\n",
    "    progress_reward = (progress / steps) * 10 if steps > 0 else 0\n",
    "\n",
    "    # Combinação ponderada das recompensas\n",
    "    reward = (center_reward * 3) + (speed_reward * 2) + (steering_penalty) + (progress_reward * 0.5)\n",
    "\n",
    "    return float(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Class to store previous parameters\n",
    "class PARAMS:\n",
    "    prev_speed = None\n",
    "    prev_steering_angle = None\n",
    "    prev_direction_diff = None\n",
    "    prev_normalized_distance_from_route = None\n",
    "    unpardonable_action = False\n",
    "\n",
    "def reward_function(params):\n",
    "    \"\"\"\n",
    "    Reward function for smoother driving without unsafe parameters like 'next_waypoint'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract safe parameters\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    steering_angle = params['steering_angle']\n",
    "    speed = params['speed']\n",
    "    heading = params['heading']\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "\n",
    "    # Penalize if off-track\n",
    "    if not all_wheels_on_track:\n",
    "        return 1e-3\n",
    "\n",
    "    # Reward for staying near the center of the track\n",
    "    center_reward = max(1e-3, 1 - (distance_from_center / (0.5 * track_width))**0.4)\n",
    "\n",
    "    # Reward for consistent speed\n",
    "    if PARAMS.prev_speed is not None:\n",
    "        speed_diff = abs(speed - PARAMS.prev_speed)\n",
    "        speed_reward = max(1e-3, 1 - speed_diff / 2)  # Penalize large speed variations\n",
    "    else:\n",
    "        speed_reward = 1.0\n",
    "\n",
    "    # Reward for smooth steering\n",
    "    if PARAMS.prev_steering_angle is not None:\n",
    "        steering_change = abs(steering_angle - PARAMS.prev_steering_angle)\n",
    "        steering_reward = max(1e-3, 1 - steering_change / 15)  # Penalize sharp turns\n",
    "    else:\n",
    "        steering_reward = 1.0\n",
    "\n",
    "    # Combine rewards\n",
    "    reward = (center_reward * 2) + (speed_reward * 3) + (steering_reward * 2)\n",
    "\n",
    "    # Apply unpardonable action penalty\n",
    "    if PARAMS.unpardonable_action:\n",
    "        reward = 1e-3\n",
    "\n",
    "    # Update previous state\n",
    "    PARAMS.prev_speed = speed\n",
    "    PARAMS.prev_steering_angle = steering_angle\n",
    "    PARAMS.prev_normalized_distance_from_route = distance_from_center\n",
    "\n",
    "    return float(reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
